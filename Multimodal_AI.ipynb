{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###### **Load the Data**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "ws = Workspace.from_config() \n",
        "dataset = Dataset.get_by_name(ws, name=\"OpenI_dataset\", version='1')\n",
        "\n",
        "dataset.download(target_path=\"data/\", overwrite=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749761664770
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "reports_df = pd.read_csv(\"data/indiana_reports.csv\")\n",
        "projections_df = pd.read_csv(\"data/indiana_projections.csv\")\n",
        "\n",
        "print(reports_df.head())\n",
        "print(projections_df.head())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "   uid                                               MeSH  \\\n0    1                                             normal   \n1    2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n2    3                                             normal   \n3    4  Pulmonary Disease, Chronic Obstructive;Bullous...   \n4    5  Osteophyte/thoracic vertebrae/multiple/small;T...   \n\n                                            Problems  \\\n0                                             normal   \n1                      Cardiomegaly;Pulmonary Artery   \n2                                             normal   \n3  Pulmonary Disease, Chronic Obstructive;Bullous...   \n4                         Osteophyte;Thickening;Lung   \n\n                                               image  \\\n0                          Xray Chest PA and Lateral   \n1                Chest, 2 views, frontal and lateral   \n2                          Xray Chest PA and Lateral   \n3  PA and lateral views of the chest XXXX, XXXX a...   \n4                          Xray Chest PA and Lateral   \n\n                                          indication      comparison  \\\n0                                   Positive TB test           None.   \n1                           Preop bariatric surgery.           None.   \n2  rib pain after a XXXX, XXXX XXXX steps this XX...             NaN   \n3                      XXXX-year-old XXXX with XXXX.  None available   \n4                        Chest and nasal congestion.             NaN   \n\n                                            findings  \\\n0  The cardiac silhouette and mediastinum size ar...   \n1  Borderline cardiomegaly. Midline sternotomy XX...   \n2                                                NaN   \n3  There are diffuse bilateral interstitial and a...   \n4  The cardiomediastinal silhouette and pulmonary...   \n\n                                          impression  \n0                               Normal chest x-XXXX.  \n1                       No acute pulmonary findings.  \n2  No displaced rib fractures, pneumothorax, or p...  \n3  1. Bullous emphysema and interstitial fibrosis...  \n4              No acute cardiopulmonary abnormality.  \n   uid                filename projection\n0    1  1_IM-0001-4001.dcm.png    Frontal\n1    1  1_IM-0001-3001.dcm.png    Lateral\n2    2  2_IM-0652-1001.dcm.png    Frontal\n3    2  2_IM-0652-2001.dcm.png    Lateral\n4    3  3_IM-1384-1001.dcm.png    Frontal\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1749761665079
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reports_df = reports_df.dropna(subset=['findings', 'impression'])\n",
        "projections_df['projection'] = projections_df['projection'].str.lower()\n",
        "frontal_df = projections_df[projections_df['projection'] == 'frontal']\n",
        "\n",
        "merged_df = pd.merge(reports_df, frontal_df, on='uid')\n",
        "merged_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "   uid                                               MeSH  \\\n0    1                                             normal   \n1    2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n2    4  Pulmonary Disease, Chronic Obstructive;Bullous...   \n3    5  Osteophyte/thoracic vertebrae/multiple/small;T...   \n4    6                                             normal   \n\n                                            Problems  \\\n0                                             normal   \n1                      Cardiomegaly;Pulmonary Artery   \n2  Pulmonary Disease, Chronic Obstructive;Bullous...   \n3                         Osteophyte;Thickening;Lung   \n4                                             normal   \n\n                                               image  \\\n0                          Xray Chest PA and Lateral   \n1                Chest, 2 views, frontal and lateral   \n2  PA and lateral views of the chest XXXX, XXXX a...   \n3                          Xray Chest PA and Lateral   \n4          PA and Lateral Chest. XXXX, XXXX at XXXX    \n\n                      indication      comparison  \\\n0               Positive TB test           None.   \n1       Preop bariatric surgery.           None.   \n2  XXXX-year-old XXXX with XXXX.  None available   \n3    Chest and nasal congestion.             NaN   \n4         Evaluate for infection      XXXX, XXXX   \n\n                                            findings  \\\n0  The cardiac silhouette and mediastinum size ar...   \n1  Borderline cardiomegaly. Midline sternotomy XX...   \n2  There are diffuse bilateral interstitial and a...   \n3  The cardiomediastinal silhouette and pulmonary...   \n4  Heart size and mediastinal contour are within ...   \n\n                                          impression  \\\n0                               Normal chest x-XXXX.   \n1                       No acute pulmonary findings.   \n2  1. Bullous emphysema and interstitial fibrosis...   \n3              No acute cardiopulmonary abnormality.   \n4                 No acute cardiopulmonary findings.   \n\n                    filename projection  \n0     1_IM-0001-4001.dcm.png    frontal  \n1     2_IM-0652-1001.dcm.png    frontal  \n2     4_IM-2050-1001.dcm.png    frontal  \n3  5_IM-2117-1003002.dcm.png    frontal  \n4     6_IM-2192-1001.dcm.png    frontal  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>MeSH</th>\n      <th>Problems</th>\n      <th>image</th>\n      <th>indication</th>\n      <th>comparison</th>\n      <th>findings</th>\n      <th>impression</th>\n      <th>filename</th>\n      <th>projection</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>Xray Chest PA and Lateral</td>\n      <td>Positive TB test</td>\n      <td>None.</td>\n      <td>The cardiac silhouette and mediastinum size ar...</td>\n      <td>Normal chest x-XXXX.</td>\n      <td>1_IM-0001-4001.dcm.png</td>\n      <td>frontal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n      <td>Cardiomegaly;Pulmonary Artery</td>\n      <td>Chest, 2 views, frontal and lateral</td>\n      <td>Preop bariatric surgery.</td>\n      <td>None.</td>\n      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n      <td>No acute pulmonary findings.</td>\n      <td>2_IM-0652-1001.dcm.png</td>\n      <td>frontal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n      <td>PA and lateral views of the chest XXXX, XXXX a...</td>\n      <td>XXXX-year-old XXXX with XXXX.</td>\n      <td>None available</td>\n      <td>There are diffuse bilateral interstitial and a...</td>\n      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n      <td>4_IM-2050-1001.dcm.png</td>\n      <td>frontal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>Osteophyte/thoracic vertebrae/multiple/small;T...</td>\n      <td>Osteophyte;Thickening;Lung</td>\n      <td>Xray Chest PA and Lateral</td>\n      <td>Chest and nasal congestion.</td>\n      <td>NaN</td>\n      <td>The cardiomediastinal silhouette and pulmonary...</td>\n      <td>No acute cardiopulmonary abnormality.</td>\n      <td>5_IM-2117-1003002.dcm.png</td>\n      <td>frontal</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>PA and Lateral Chest. XXXX, XXXX at XXXX</td>\n      <td>Evaluate for infection</td>\n      <td>XXXX, XXXX</td>\n      <td>Heart size and mediastinal contour are within ...</td>\n      <td>No acute cardiopulmonary findings.</td>\n      <td>6_IM-2192-1001.dcm.png</td>\n      <td>frontal</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1749761665183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df[\"report_text\"] = merged_df[\"findings\"].fillna('') + \" \" + merged_df[\"impression\"].fillna('')\n",
        "merged_df = merged_df.drop_duplicates(subset=['filename'])\n",
        "merged_df = merged_df.reset_index(drop=True)\n",
        "merged_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "   uid                                               MeSH  \\\n0    1                                             normal   \n1    2  Cardiomegaly/borderline;Pulmonary Artery/enlarged   \n2    4  Pulmonary Disease, Chronic Obstructive;Bullous...   \n3    5  Osteophyte/thoracic vertebrae/multiple/small;T...   \n4    6                                             normal   \n\n                                            Problems  \\\n0                                             normal   \n1                      Cardiomegaly;Pulmonary Artery   \n2  Pulmonary Disease, Chronic Obstructive;Bullous...   \n3                         Osteophyte;Thickening;Lung   \n4                                             normal   \n\n                                               image  \\\n0                          Xray Chest PA and Lateral   \n1                Chest, 2 views, frontal and lateral   \n2  PA and lateral views of the chest XXXX, XXXX a...   \n3                          Xray Chest PA and Lateral   \n4          PA and Lateral Chest. XXXX, XXXX at XXXX    \n\n                      indication      comparison  \\\n0               Positive TB test           None.   \n1       Preop bariatric surgery.           None.   \n2  XXXX-year-old XXXX with XXXX.  None available   \n3    Chest and nasal congestion.             NaN   \n4         Evaluate for infection      XXXX, XXXX   \n\n                                            findings  \\\n0  The cardiac silhouette and mediastinum size ar...   \n1  Borderline cardiomegaly. Midline sternotomy XX...   \n2  There are diffuse bilateral interstitial and a...   \n3  The cardiomediastinal silhouette and pulmonary...   \n4  Heart size and mediastinal contour are within ...   \n\n                                          impression  \\\n0                               Normal chest x-XXXX.   \n1                       No acute pulmonary findings.   \n2  1. Bullous emphysema and interstitial fibrosis...   \n3              No acute cardiopulmonary abnormality.   \n4                 No acute cardiopulmonary findings.   \n\n                    filename projection  \\\n0     1_IM-0001-4001.dcm.png    frontal   \n1     2_IM-0652-1001.dcm.png    frontal   \n2     4_IM-2050-1001.dcm.png    frontal   \n3  5_IM-2117-1003002.dcm.png    frontal   \n4     6_IM-2192-1001.dcm.png    frontal   \n\n                                         report_text  \n0  The cardiac silhouette and mediastinum size ar...  \n1  Borderline cardiomegaly. Midline sternotomy XX...  \n2  There are diffuse bilateral interstitial and a...  \n3  The cardiomediastinal silhouette and pulmonary...  \n4  Heart size and mediastinal contour are within ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>MeSH</th>\n      <th>Problems</th>\n      <th>image</th>\n      <th>indication</th>\n      <th>comparison</th>\n      <th>findings</th>\n      <th>impression</th>\n      <th>filename</th>\n      <th>projection</th>\n      <th>report_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>Xray Chest PA and Lateral</td>\n      <td>Positive TB test</td>\n      <td>None.</td>\n      <td>The cardiac silhouette and mediastinum size ar...</td>\n      <td>Normal chest x-XXXX.</td>\n      <td>1_IM-0001-4001.dcm.png</td>\n      <td>frontal</td>\n      <td>The cardiac silhouette and mediastinum size ar...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Cardiomegaly/borderline;Pulmonary Artery/enlarged</td>\n      <td>Cardiomegaly;Pulmonary Artery</td>\n      <td>Chest, 2 views, frontal and lateral</td>\n      <td>Preop bariatric surgery.</td>\n      <td>None.</td>\n      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n      <td>No acute pulmonary findings.</td>\n      <td>2_IM-0652-1001.dcm.png</td>\n      <td>frontal</td>\n      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n      <td>Pulmonary Disease, Chronic Obstructive;Bullous...</td>\n      <td>PA and lateral views of the chest XXXX, XXXX a...</td>\n      <td>XXXX-year-old XXXX with XXXX.</td>\n      <td>None available</td>\n      <td>There are diffuse bilateral interstitial and a...</td>\n      <td>1. Bullous emphysema and interstitial fibrosis...</td>\n      <td>4_IM-2050-1001.dcm.png</td>\n      <td>frontal</td>\n      <td>There are diffuse bilateral interstitial and a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>Osteophyte/thoracic vertebrae/multiple/small;T...</td>\n      <td>Osteophyte;Thickening;Lung</td>\n      <td>Xray Chest PA and Lateral</td>\n      <td>Chest and nasal congestion.</td>\n      <td>NaN</td>\n      <td>The cardiomediastinal silhouette and pulmonary...</td>\n      <td>No acute cardiopulmonary abnormality.</td>\n      <td>5_IM-2117-1003002.dcm.png</td>\n      <td>frontal</td>\n      <td>The cardiomediastinal silhouette and pulmonary...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>PA and Lateral Chest. XXXX, XXXX at XXXX</td>\n      <td>Evaluate for infection</td>\n      <td>XXXX, XXXX</td>\n      <td>Heart size and mediastinal contour are within ...</td>\n      <td>No acute cardiopulmonary findings.</td>\n      <td>6_IM-2192-1001.dcm.png</td>\n      <td>frontal</td>\n      <td>Heart size and mediastinal contour are within ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1749761665256
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv(\"data/cleaned_metadata.csv\", index=False)\n",
        "\n",
        "merged_df[[\"uid\", \"filename\", \"report_text\"]].head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "   uid                   filename  \\\n0    1     1_IM-0001-4001.dcm.png   \n1    2     2_IM-0652-1001.dcm.png   \n2    4     4_IM-2050-1001.dcm.png   \n3    5  5_IM-2117-1003002.dcm.png   \n4    6     6_IM-2192-1001.dcm.png   \n\n                                         report_text  \n0  The cardiac silhouette and mediastinum size ar...  \n1  Borderline cardiomegaly. Midline sternotomy XX...  \n2  There are diffuse bilateral interstitial and a...  \n3  The cardiomediastinal silhouette and pulmonary...  \n4  Heart size and mediastinal contour are within ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>filename</th>\n      <th>report_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1_IM-0001-4001.dcm.png</td>\n      <td>The cardiac silhouette and mediastinum size ar...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2_IM-0652-1001.dcm.png</td>\n      <td>Borderline cardiomegaly. Midline sternotomy XX...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>4_IM-2050-1001.dcm.png</td>\n      <td>There are diffuse bilateral interstitial and a...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>5_IM-2117-1003002.dcm.png</td>\n      <td>The cardiomediastinal silhouette and pulmonary...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>6_IM-2192-1001.dcm.png</td>\n      <td>Heart size and mediastinal contour are within ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1749761665534
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (4.52.4)\r\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (3.18.0)\r\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (0.32.4)\r\nRequirement already satisfied: numpy>=1.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (1.23.5)\r\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (24.2)\r\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (6.0.2)\r\nRequirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (2024.11.6)\r\nRequirement already satisfied: requests in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (2.32.3)\r\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (0.21.1)\r\nRequirement already satisfied: safetensors>=0.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (0.5.3)\r\nRequirement already satisfied: tqdm>=4.27 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from transformers) (4.67.1)\r\nRequirement already satisfied: fsspec>=2023.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.10.0)\r\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\r\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\r\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers) (3.10)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1749761665921
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.7.1)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (4.13.2)\nRequirement already satisfied: sympy>=1.13.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (1.14.0)\nRequirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (2023.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (3.3.1)\nRequirement already satisfied: setuptools>=40.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from triton==3.3.1->torch) (75.8.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1749761667392
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install quiet"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[31mERROR: Could not find a version that satisfies the requirement quiet (from versions: none)\u001b[0m\u001b[31m\r\n\u001b[0m\u001b[31mERROR: No matching distribution found for quiet\u001b[0m\u001b[31m\r\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1749761668138
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Text Embeddings**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "df = pd.read_csv(\"data/cleaned_metadata.csv\")\n",
        "\n",
        "model_name='dmis-lab/biobert-base-cased-v1.1'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "model.eval()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n    (position_embeddings): Embedding(512, 768)\n    (token_type_embeddings): Embedding(2, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1749761675094
        },
        "jupyter": {
          "outputs_hidden": false
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_biobert_embedding(text):\n",
        "    inputs= tokenizer(text, return_tensors='pt', truncation = True,padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1749761675161
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Generating Text Embeddings**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings = []\n",
        "\n",
        "for text in tqdm(df[\"report_text\"], desc=\"Generating BioBERT embeddings\"):\n",
        "    emb = get_biobert_embedding(text)\n",
        "    embeddings.append(emb)\n",
        "\n",
        "text_embeddings = np.stack(embeddings)\n",
        "\n",
        "np.save(\"data/biobert_text_embeddings.npy\", text_embeddings)\n",
        "\n",
        "print(\"✅ Text embeddings generated and saved as 'biobert_text_embeddings.npy'\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Generating BioBERT embeddings:  99%|█████████▊| 3258/3301 [05:17<00:04,  9.69it/s]"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Text embeddings generated and saved as 'biobert_text_embeddings.npy'\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1749761996873
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Image Embeddings with DenseNet**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: torchvision in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.22.1)\r\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torchvision) (1.23.5)\r\nRequirement already satisfied: torch==2.7.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torchvision) (2.7.1)\r\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torchvision) (11.2.1)\r\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (3.18.0)\r\nRequirement already satisfied: typing-extensions>=4.10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (4.13.2)\r\nRequirement already satisfied: sympy>=1.13.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (1.14.0)\r\nRequirement already satisfied: networkx in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (3.4.2)\r\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (3.1.6)\r\nRequirement already satisfied: fsspec in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (2023.10.0)\r\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (12.6.77)\r\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (12.6.77)\r\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (12.6.80)\r\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (9.5.1.17)\r\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (12.6.4.1)\r\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (11.3.0.4)\r\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (10.3.7.77)\r\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (11.7.1.2)\r\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (12.5.4.2)\r\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (0.6.3)\r\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (2.26.2)\r\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (12.6.77)\r\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (12.6.85)\r\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (1.11.1.6)\r\nRequirement already satisfied: triton==3.3.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch==2.7.1->torchvision) (3.3.1)\r\nRequirement already satisfied: setuptools>=40.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from triton==3.3.1->torch==2.7.1->torchvision) (75.8.0)\r\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->torch==2.7.1->torchvision) (3.0.2)\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1749761998463
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pillow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: pillow in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (11.2.1)\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1749761999868
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "\n",
        "image_dir = \"data/images/images_normalized/\"\n",
        "\n",
        "df = pd.read_csv(\"data/cleaned_metadata.csv\")\n",
        "\n",
        "df[\"image_path\"] = df[\"filename\"].apply(lambda x: os.path.join(image_dir, x))\n",
        "df = df[df[\"image_path\"].apply(os.path.exists)].reset_index(drop=True)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1749762010088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "densenet = models.densenet121(pretrained=True)\n",
        "feature_extractor = torch.nn.Sequential(*list(densenet.features.children()))\n",
        "feature_extractor.eval()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749762842918
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_embeddings = []\n",
        "\n",
        "for img_path in tqdm(df[\"image_path\"], desc=\"Generating DenseNet embeddings\"):\n",
        "    try:\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        input_tensor = image_transform(image).unsqueeze(0) \n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = feature_extractor(input_tensor)\n",
        "            pooled = torch.nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
        "            embedding = pooled.view(-1).numpy()\n",
        "            image_embeddings.append(embedding)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path}: {e}\")\n",
        "        image_embeddings.append(np.zeros(1024))  \n",
        "print(image_embeddings)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749763458268
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "image_embeddings = np.stack(image_embeddings)\n",
        "np.save(\"data/densenet_image_embeddings.npy\", image_embeddings)\n",
        "\n",
        "print(\"✅ Image embeddings saved as 'densenet_image_embeddings.npy'\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Image embeddings saved as 'densenet_image_embeddings.npy'\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1749763458338
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Load and Combine both the Embeddings**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"data/cleaned_metadata.csv\")\n",
        "\n",
        "\n",
        "text_embeddings = np.load(\"data/biobert_text_embeddings.npy\")\n",
        "image_embeddings = np.load(\"data/densenet_image_embeddings.npy\")\n",
        "\n",
        "print(\"Text embeddings:\", text_embeddings.shape)\n",
        "print(\"Image embeddings:\", image_embeddings.shape)\n",
        "print(\"Metadata rows:\", len(df))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Text embeddings: (3301, 768)\nImage embeddings: (3301, 1024)\nMetadata rows: 3301\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1749763458666
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y faiss-cpu faiss-gpu\n",
        "!pip install faiss-cpu==1.7.4 "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing installation: faiss-cpu 1.7.4\nUninstalling faiss-cpu-1.7.4:\n  Successfully uninstalled faiss-cpu-1.7.4\n\u001b[33mWARNING: Skipping faiss-gpu as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mCollecting faiss-cpu==1.7.4\n  Using cached faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\nInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.7.4\n"
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy==1.23.5"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: numpy==1.23.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.23.5)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1749763466018
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "\n",
        "text_embeddings_norm = normalize(text_embeddings)\n",
        "image_embeddings_norm = normalize(image_embeddings)\n",
        "\n",
        "\n",
        "combined = np.concatenate([0.6 * text_embeddings_norm, 0.4 * image_embeddings_norm], axis=1)\n",
        "\n",
        "combined_embeddings = np.array(combined, dtype=np.float32, copy=True)\n"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1749763466103
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "combined_embeddings = np.ascontiguousarray(combined_embeddings, dtype=np.float32)\n",
        "\n",
        "d = combined_embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(d)\n",
        "index.add(combined_embeddings)\n",
        "\n",
        "print(\"✅ FAISS index successfully created with\", index.ntotal, \"entries\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ FAISS index successfully created with 3301 entries\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1749763466166
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_similar_cases(query_text, image_embedding, top_k=5):\n",
        "    from transformers import AutoTokenizer, AutoModel\n",
        "    import torch\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "    model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "    model.eval()\n",
        "\n",
        "    inputs = tokenizer(query_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    query_text_emb = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
        "\n",
        "    if image_embedding is not None:\n",
        "        query_text_emb = normalize(query_text_emb.reshape(1, -1))\n",
        "        image_embedding = normalize(image_embedding.reshape(1, -1))\n",
        "        query_vector = np.concatenate([0.6 * text_embeddings_norm, 0.4 * image_embeddings_norm], axis=1)\n",
        "    else:\n",
        "        query_vector = normalize(query_text_emb.reshape(1, -1))\n",
        "\n",
        "    D, I = index.search(query_vector.astype(np.float32), top_k)\n",
        "\n",
        "    results = df.iloc[I[0]][[\"filename\", \"report_text\"]]\n",
        "    return results\n"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1749763466232
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = retrieve_similar_cases(\n",
        "    query_text=\"patient with diffuse bilateral opacities in the lungs\",\n",
        "    image_embedding=image_embeddings[0] \n",
        ")\n",
        "print(\"Top matching cases:\")\n",
        "print(results)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Top matching cases:\n                            filename  \\\n0             1_IM-0001-4001.dcm.png   \n1744  2097_IM-0727-1001-0001.dcm.png   \n2854       3466_IM-1683-1001.dcm.png   \n2283       2784_IM-1220-1001.dcm.png   \n2577       3137_IM-1476-1001.dcm.png   \n\n                                            report_text  \n0     The cardiac silhouette and mediastinum size ar...  \n1744  The trachea is midline. Cardiomediastinal silh...  \n2854  The cardiomediastinal silhouette is normal in ...  \n2283  The heart is normal in size and contour. There...  \n2577  The trachea is midline. Cardiomediastinal silh...  \n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1749763467682
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Format the RAG Context Prompt**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_rag_prompt(user_query,image_embedding, retrieved_reports):\n",
        "    context = \"\\n\\n\".join(retrieved_reports[\"report_text\"].tolist())\n",
        "    prompt = f\"\"\"\n",
        "You are a clinical assistant. Based on the following historical radiology reports and the user question, generate a clinical summary with a focus on possible diagnoses, severity, and recommended actions.\n",
        "\n",
        "User Question:\n",
        "{user_query}\n",
        "{image_embedding}\n",
        "\n",
        "Relevant Historical Reports:\n",
        "{context}\n",
        "\n",
        "Clinical Summary:\n",
        "\"\"\"\n",
        "    return prompt\n"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1749763467765
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Using Hugging Face Transformers**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sacremoses"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: sacremoses in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (0.1.1)\nRequirement already satisfied: regex in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sacremoses) (2024.11.6)\nRequirement already satisfied: click in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sacremoses) (8.1.8)\nRequirement already satisfied: joblib in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sacremoses) (1.4.2)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from sacremoses) (4.67.1)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1749763469148
        },
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_name = \"microsoft/BioGPT-Large\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "bio_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The Device set to use cpu\ncurrent process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1749763473069
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_biogpt(prompt):\n",
        "    output = bio_pipeline(prompt, max_new_tokens=300, do_sample=True)[0][\"generated_text\"]\n",
        "    return output"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1749763473152
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Files in current directory:\", os.listdir(\".\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Files in current directory: ['.amlignore', '.amlignore.amltmp', '.git', '.gradio', '.ipynb_aml_checkpoints', 'data', 'key', 'key.pub', 'Multimodal_AI.ipynb', 'multimodal_ai.ipynb.amltmp', 'requirements.txt', 'requirements.txt.amltmp', 'test_image.png', 'X-RayGPT-A-Biomedical-RAG-Chatbot-for-Radiology-Report-Generation-and-Severity-Prediction']\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1749763473221
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "from torchvision import models\n",
        "densenet = models.densenet121(pretrained=True)\n",
        "feature_extractor = torch.nn.Sequential(*list(densenet.features.children()))\n",
        "feature_extractor.eval()\n",
        "\n",
        "\n",
        "def extract_embedding_from_image(image):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = image_transform(image).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        features = feature_extractor(input_tensor)\n",
        "        pooled = torch.nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
        "        embedding = pooled.view(-1).numpy()\n",
        "\n",
        "    return embedding\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1749763473279
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"test_image.png\" \n",
        "image_emb = extract_embedding_from_image(image_path)\n"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1749763473349
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"The patient exhibits signs of chronic obstructive pulmonary disease with increased interstitial markings.\"\n",
        "\n",
        "\n",
        "top_k_reports = retrieve_similar_cases(query_text=query,image_embedding=image_emb, top_k=5)\n",
        "\n",
        "prompt = build_rag_prompt(query, image_emb, top_k_reports)\n",
        "\n",
        "response = generate_response_biogpt(prompt)  \n",
        "\n",
        "print(\"🧠 AI Clinical Assistant Response:\\n\")\n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "🧠 AI Clinical Assistant Response:\n\n\nYou are a clinical assistant. Based on the following historical radiology reports and the user question, generate a clinical summary with a focus on possible diagnoses, severity, and recommended actions.\n\nUser Question:\nThe patient exhibits signs of chronic obstructive pulmonary disease with increased interstitial markings.\n[-1.09165514e-04  2.69876327e-03  2.19170586e-03 ...  1.17157161e+00\n  2.28229165e-01 -9.04489085e-02]\n\nRelevant Historical Reports:\nThe cardiac silhouette and mediastinum size are within normal limits. There is no pulmonary edema. There is no focal consolidation. There are no XXXX of a pleural effusion. There is no evidence of pneumothorax. Normal chest x-XXXX.\n\nThe trachea is midline. Cardiomediastinal silhouette is normal. The lungs are clear without evidence of acute infiltrate or effusion. There is no pneumothorax. The visualized bony structures reveal no abnormalities. No acute cardiopulmonary abnormality seen on chest x-XXXX. No pneumothorax.\n\nThe cardiomediastinal silhouette is normal in size and contour. Streaky perihilar opacities. Peribronchial cuffing also noted. No focal consolidation, pneumothorax or large pleural effusion. Normal XXXX. Findings most suggestive of infectious or reactive small airways disease. No focal pneumonia.\n\nThe heart is normal in size and contour. There is no mediastinal widening. The lungs are clear bilaterally. No large pleural effusion or pneumothorax. The XXXX are intact. No acute cardiopulmonary abnormalities.\n\nThe trachea is midline. Cardiomediastinal silhouette is normal. There is a calcified density in the left mid lung, most XXXX a calcified granuloma. Lungs are otherwise clear, without evidence of acute infiltrate or effusion. Specifically, there is no evidence of tuberculous disease. There is no pneumothorax. The bony structures show no acute abnormalities. No acute cardiopulmonary abnormalities. No active pulmonary disease.\n\nClinical Summary:\n You are a clinical assistant. Based on the following historical radiology reports and the user question, generate a clinical summary with a focus on possible diagnoses, severity, and recommended actions. User Question: The patient exhibits signs of chronic obstructive pulmonary disease with increased interstitial markings. < / FREETEXT > < / ABSTRACT > ▃\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1749763503244
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: gradio in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (5.33.0)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (24.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (4.9.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.115.12)\nRequirement already satisfied: ffmpy in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.6.0)\nRequirement already satisfied: gradio-client==1.10.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (1.10.2)\nRequirement already satisfied: groovy~=0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.1.2)\nRequirement already satisfied: httpx>=0.24.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.32.4)\nRequirement already satisfied: jinja2<4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (1.23.5)\nRequirement already satisfied: orjson~=3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (3.10.18)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (24.2)\nRequirement already satisfied: pandas<3.0,>=1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (1.5.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (11.2.1)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (2.11.3)\nRequirement already satisfied: pydub in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.18 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.0.20)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (6.0.2)\nRequirement already satisfied: ruff>=0.9.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.11.13)\nRequirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.46.2)\nRequirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.13.3)\nRequirement already satisfied: typer<1.0,>=0.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.16.0)\nRequirement already satisfied: typing-extensions~=4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (4.13.2)\nRequirement already satisfied: uvicorn>=0.14.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio) (0.34.2)\nRequirement already satisfied: fsspec in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio-client==1.10.2->gradio) (2023.10.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gradio-client==1.10.2->gradio) (15.0.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from huggingface-hub>=0.28.1->gradio) (1.1.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: click>=8.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\nRequirement already satisfied: mdurl~=0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1749763504770
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nbformat"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: nbformat in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (5.10.4)\nRequirement already satisfied: fastjsonschema>=2.15 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nbformat) (2.21.1)\nRequirement already satisfied: jsonschema>=2.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nbformat) (4.23.0)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nbformat) (5.7.2)\nRequirement already satisfied: traitlets>=5.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nbformat) (5.14.3)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat) (0.24.0)\nRequirement already satisfied: platformdirs>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.3.7)\nRequirement already satisfied: typing-extensions>=4.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.13.2)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1749763506187
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def multimodal_rag_chat(text_query, image):\n",
        "    image_emb = extract_embedding_from_image(image) if image else None\n",
        "    top_k = retrieve_similar_cases(text_query, image_embedding=image_emb)\n",
        "    prompt = build_rag_prompt(text_query, top_k)\n",
        "    response = generate_response_biogpt(prompt) \n",
        "    return response\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=multimodal_rag_chat,\n",
        "    inputs=[gr.Textbox(label=\"Clinical Query\"), gr.Image(label=\"Optional Chest X-ray\")],\n",
        "    outputs=\"text\",\n",
        "    title=\"AI Clinical Assistant\",\n",
        "    description=\"Ask a question and optionally upload an X-ray image\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749763509891
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}